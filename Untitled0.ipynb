{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " **Data Extraction in ETL**\n"
      ],
      "metadata": {
        "id": "n9YiGwJrLNKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 . ETL process pull data from various sources\n",
        "  - Relational databases - structured tables with SQL Queries.\n",
        "  - Flat files - simple text or spreadsheet files.\n",
        "  - No SQL databases - document or key-value stores.\n",
        "  - APLs/web services - real-time data from external systems.\n",
        "  - Cloud storage -large unstructured files or logs .\n",
        "  - Enterprise applications - proprietary data formates .\n",
        "\n",
        "2 . Data extraction is the process of retrieving raw data from source\n",
        "    system . in the ETL pipeline it is the first step extract , transfrom, load , pulling data into a staging area for cleaning transformation and eventual loading into a target data werehouse.\n",
        "\n",
        "3 . CSV - Is a plain-text file with delimited data extraction is simple and\n",
        "          fast , but it lacks metadata and data-type information\n",
        "  - Excel - Is a binary spreadsheet that can store formatting ,formulas, and multiple sheets . extraction requires handing file-specific libraies and may need sheet-level parsing . In  ETL ,CSV is usually preferred for its simplicity and size efficiency , while excel needs extra processing structure and type conversion .\n",
        "\n",
        "4 . Connect to the database using a drive/connection string .\n",
        "   - Write an SQL query to select the required data.\n",
        "   - Execute the query and fetch results into a staging table or file\n",
        "   - Handle incremental extraction using timestamps or change-tracking.\n",
        "   - Validate data integrity and error-check the extraction process.\n",
        "\n",
        "5 .  perfomance - handling large volume can cause show queries or timeouts.\n",
        "     Data quality - dealing with missing inconsistent or corrupted source\n",
        "     data.\n",
        "     schema changes - source structure updates can break extraction logic.\n",
        "6 . APls are protocols that enable applications to communicate .\n",
        "    In real-time extraction,REST or SOAP APLs provide progammatic access\n",
        "    to live data, allowing ETL tools to fetch updated information on demand\n",
        "    via HTTP requests , often JSON or XML responses .\n",
        "\n",
        "7 . databases offer structured indexed data with query optimization ensure\n",
        "    reliable secure and scalable access .\n",
        "\n",
        "8 . chunk - the file to avoid memory overload .\n",
        "    use - optimized libaries with chunk size or streaming parsers .\n",
        "    validation - data type and handle encoding issues early .\n",
        "    apply - incremental processing and resocessing or filter rows to reduce\n",
        "    load .\n",
        "    monitor - perfomance and resource usages to tune extraction speed .\n",
        "    "
      ],
      "metadata": {
        "id": "UlJ87Br7LZoI"
      }
    }
  ]
}